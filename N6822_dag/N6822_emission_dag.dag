#!/usr/bin/env N6822_emssion.dag.dag

## TRANSFER STAGED MEASUREMENT SETS

## transfer.sub to transfer measurement sets from Google Drive using rclone
## executable:
## - transfer.sh
## inputs:
## - src_name: source name
## output:
## - tarball measurement set
#JOB A transfer.sub
#VARS A src_name="WLM"
#PARENT A CHILD B

## run split_spw.sub to split off the HI or OH spectral windows
## executable:
## - split_spw.sh (runs split_spw.py)
## inputs: 
## - ms_name: file name in input textfile
## - src_name: source name in input textfile
## - src_config: source and config (prefix on file name from Google drive)
## - spw_str: string denoting spectral window to be split ('5' for HI line)
## output:
## - tarball of measurement sets that have had spectral window split out with 'spw#' where # is the spectral window index appended to name
#JOB B split_spw.sub
#VARS B src_name="NGC6822" v_sys="-44" v_width="210" rest_freq="1.420406"
#PARENT B CHILD C

## place all split-out measurement sets on same spectral axis & reference frame
## executable:
## - ms_transform.sh (runs ms_transform.py)
## inputs:
## - ms_name: file name in textfile
## - ref_frame: output reference frame (e.g., 'LSRK' or 'BARY')
## - chan_width: channel width in units of Hz
## - src_name: source name
## output:
## - tarball of measurement sets that have been transformed to the user provided reference frame and spectral channel width
#JOB C ms_transform.sub
#VARS C ref_frame="LSRK" chan_width="1953.71094083786" src_name="NGC6822"
#PARENT C CHILD D

## re-weight visibilities based on root mean square noise in emission-free regions. Use systemic velocity and velocity width to mask channels with expected emission. 
## executable:
## - statwt_indv.sh (runs statwt_indv.py)
## arguments:
## - ms_name: file name in textfile
## - v_sys: systemic velocity of source
## - v_width: velocity width of source
## - src_name: source name
## output:
## - tarball of re-weighted, transformed, and split-out measurement sets with '.wt' appended to tarball name
## JOB D statwt.sub
## VARS D v_sys="-44" v_width="210" src_name="NGC6822"
## PARENT D CHILD E

## CONTSUB
## run continuum subtraction for all measurement sets from all VLA configurations
## executable:
## - uvcontsub_indv.sh (runs uvcontsub.py)
## arguments:
## - ms_name: file name in textfil
## - v_sys: systemic velocity of source
## - v_width: velocity width of source
## - src_name: source name
## output:
## - contsubed measurement sets with '.contsub' suffix appended
## JOB E uvcontsub_all.sub
## VARS E src_name="NGC6822" v_sys="-44" v_width="210"
## PARENT E CHILD F

## GENERATE INPUT  FOR SPLIT CONCAT STEP
## call generate_spit_file.py to generate input for SPLIT OF CONCAT step
## executable:
## - generate_spit_file.sh (runs generate_spit_file.py)
## arguments:
## - src_name: source name
## - extension: file extension for measurement sets to be analyzed
## - output: output name for generated csv file
## output:
## - a csv file that has three columns: name of measurement set, starting channel to split, ending channel to split for concat
##JOB F generate_spit_filesub
##VARS F src_name="NGC6822" extension="contsub" output="split_concat_list"

## SPLIT FOR CONCAT
## split out channels from measurement sets with more than minumum number of total channels
## to ensure all measurement sets have same number of channels for concat step (runs in staging area)
## executable:
## - split_channels_concat.sh (runs split_channels.py)
## arguments:
## - src_name: source name
## output:
## - split out measurement sets with equal number of channels so concat step will combine into a single spw
## JOB G split_channels_concat.sub
## VARS G src_name="NGC6822"

## CONCAT
## concatenate (combine) measurement sets from all VLA configurations in staging area
## executable:
## - concat.sh (runs concat.py)
## arguments:
## - outfile_name: name of concatenated measurement set
## - src_name: source name
## output:
## - concatenated measurement set in staging area
##JOB H concat_all.sub
## VARS H src_name="NGC6822" outfile_name="NGC6822_A+B+C+D.ms"

## COMBINE_SPW
## run mstransform again to combine all spectral windows in concatenated measurement set
## executable:
## - combine_spw.sh (runs combine_spw.py)
## arguments:
## - input_name: input_name of concatended measurement set
## - src_name: source name
## output:
## - concantenated measurement set with a single spectral window
## JOB I combine_spw.sub
## VARS I src_name="NGC6822" input_name="NGC6822_A+B+C+D.ms"

## SPLIT FOR IMAGING
## split out channels from concatenated measurement set for imaging
## executable:
## - split_channels.sh (runs split_channels.py)
## arguments: 
## - input_name: name of input concatenated measurement set
## - src_name: source name
## - start_chan: starting channel to split
## - end_chan: ending channel to split
## output:
## - tarballs of individual channels
JOB J split_channels.sub
VARS J input_name="NGC6822_A+B+C+D.ms" src_name="NGC6822"

## run tclean to get cubelets centered on each background source
## executable:
## - abs_cubelet.sh (runs abs_cubelet.py)
## inputs:
## - RA: Right Acension string from textfile (e.g., 00h40m13.8)
## - Dec: Declination string form textfile (e.g., +40d50m04.73)
## - ms_name: concatenated measurement set
## - start_velocity: starting LSRK velocity (km/s)
## - chan_nums: number of output channels
## - field_id: field ID for source
## - src_name: source name
## - output:
## - tarball of 2D cubelets for each source
#JOB F abs_cubelet.sub
#VARS F ms_name="WLM_A+B.ms.tar" start_velocity="-200" chan_nums="500" src_name="WLM" field_id="3"
## PARENT F CHILD G

## finally, combine the 2D images into 3-dimensional data cube (dims: sky position, sky position, frequency/velocity)
## executable:
## - combine_images.sh (runs combine_image.py)
## arguments:
## - (in combine_images.sh for combine_images.py) suffix (combine all files with *.residual, *.image, etc...)
## - (in combine_images.sh for combine_images.py) name of output data cube (in FITS format)
## - (in combine_images.sh for combine_images.py) spectral width of channels in kHz
## output:
## - final data cube
#condor_submit combine_images.sub
